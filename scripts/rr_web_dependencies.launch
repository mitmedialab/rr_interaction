<launch>
    <!-- Google ASR (for speech recognition). Needs to be run with the prefix
         "pipenv" but that doesn't work with the launch-prefix tag. -->
    <!-- <node name="google_asr_node"
          pkg="asr_google_cloud"
          type="run_ros_asr.sh" /> -->

    <!-- Audio entrainer. Has special setup so we run a script that does
         the setup and then starts the node. -->
    <node name="rr_audio_entrainer"
          pkg="rr_audio_entrainer"
          type="run_entrainer.sh" />

    <!-- Audio server -->
    <node name="audio_server"
          pkg="rr_interaction"
          type="run_audio_server.sh" />

    <!-- Rosbridge (for talking to the tablet) -->
    <include file="$(find rosbridge_server)/launch/rosbridge_websocket.launch" />

    <!-- User input GUI (for giving input to rr_interaction) -->
    <node name="rr_user_input_form"
          pkg="rr_interaction"
          cwd="node"
          type="web_ui.py" />

    <!-- Lookat node (for sending lookat commands to the robot) -->
    <node name="rr_lookat_and_affect_node"
          pkg="rr_interaction"
          type="lookat_and_affect_node.py" />

    <!-- Backchanneling. Has multiple nodes as part of it. -->
    <include file="$(find moody_backchanneling)/backchannel_module/backchannel_dependencies.launch" />

    <!-- Affect detection. -->
    <include file="$(find tega_cam_affect_analysis)/launch/tega_cam_affect_analysis_nox11.launch" />

</launch>
